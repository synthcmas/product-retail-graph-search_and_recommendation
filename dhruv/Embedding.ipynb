{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e270e9f0-d7bb-4d65-85cc-d29b293c51c7",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17eac2-5108-46bb-ad99-da82412c0ca7",
   "metadata": {},
   "source": [
    "TFIDF Embedding can not be used for vectorizing the vector for finfing the similarity with the query as it generates its courpus everytime we create TFIDF matrix which requried huge calculation to be performed everytime we need to perform similarity calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da52d2-1606-4a32-87c3-6a5fde50586c",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "92a70066-0d6c-4825-8c59-f1a7f5b14a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0379d17-4520-4b03-99ae-793eea09e00e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=ada8cc8b98fd8643ced5f03068bec79f0a4728c1c4c9ad7f7975f9f5177a98ad\n",
      "  Stored in directory: c:\\users\\dhrsingh\\appdata\\local\\pip\\cache\\wheels\\04\\5f\\3e\\46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7724a2-9832-4cd4-aac0-b8dfe8b32e9e",
   "metadata": {},
   "source": [
    "### Importing weights for embedding Google Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2eb1d03e-1d87-471a-aedf-4864281b9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(filepath, binary=True) \n",
    "#extracting words7 vectors from google news vector\n",
    "embeddings_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d3b5a169-6a51-427e-a505-f1224438868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, vector in zip(wv_from_bin.key_to_index , wv_from_bin.vectors):\n",
    "    coefs = np.asarray(vector, dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c92103d2-00ba-4dcb-982e-b5048efabcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fucntion to findout the vector space of each sentence\n",
    "\n",
    "def avg_feature_vector(sentence, model, num_features):\n",
    "    words = sentence.split()\n",
    "    #feature vector is initialized as an empty array\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in embeddings_index.keys():\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "45987c51-a3d3-4d4e-9c30-1dd83f986499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"stratified_sample_1.csv\", usecols= ['clean_detail_desc', 'prod_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f2356656-00ca-4283-9cd1-4591b93738e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>clean_detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vickan dress w</td>\n",
       "      <td>short dress airi chiffon flouncetrim vneck sew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vickan dress w</td>\n",
       "      <td>short dress airi chiffon flouncetrim vneck sew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vickan dress w</td>\n",
       "      <td>short dress airi chiffon flouncetrim vneck sew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vickan dress w</td>\n",
       "      <td>short dress airi chiffon flouncetrim vneck sew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vickan dress w</td>\n",
       "      <td>short dress airi chiffon flouncetrim vneck sew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prod_name                                  clean_detail_desc\n",
       "0  Vickan dress w  short dress airi chiffon flouncetrim vneck sew...\n",
       "1  Vickan dress w  short dress airi chiffon flouncetrim vneck sew...\n",
       "2  Vickan dress w  short dress airi chiffon flouncetrim vneck sew...\n",
       "3  Vickan dress w  short dress airi chiffon flouncetrim vneck sew...\n",
       "4  Vickan dress w  short dress airi chiffon flouncetrim vneck sew..."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "870eab2d-71f3-4ae0-9b82-ad56c1bf0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "res = random.sample(range(1, 1589416), 10)\n",
    "clean_data = df.loc[res].clean_detail_desc.tolist()\n",
    "prod_name = df.loc[res].prod_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9c970f16-9f9a-4408-b0e4-d13b535623a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>clean_detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116957</th>\n",
       "      <td>Seb overshirt</td>\n",
       "      <td>overs shirt jacket wash cotton denim collar bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81117</th>\n",
       "      <td>Jan tee</td>\n",
       "      <td>tshirt pattern cotton jersey round necklin che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760759</th>\n",
       "      <td>Orlando padded soft bra</td>\n",
       "      <td>soft nonwir bra lace adjust strap cup remov in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943975</th>\n",
       "      <td>Luna skinny 5 pkt</td>\n",
       "      <td>pocket jean wash superstretch denim regular wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979649</th>\n",
       "      <td>ZEBRA CF TVP</td>\n",
       "      <td>top lightweight sweatshirt fabric drop shoulde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401968</th>\n",
       "      <td>CALLISTO ski jkt</td>\n",
       "      <td>pad ski jacket windproof waterrepel breathabl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346390</th>\n",
       "      <td>ESSENTIAL FIONA LACE TANK</td>\n",
       "      <td>fit top soft rib cotton jersey vneck lace trim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465349</th>\n",
       "      <td>Simple as That Triangle Top</td>\n",
       "      <td>line nonwir triangl bikini top wide hem narrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143228</th>\n",
       "      <td>Ozzy Denim Shorts</td>\n",
       "      <td>highwaist short superstretch twill back pocket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015978</th>\n",
       "      <td>Shorts HW Pixie</td>\n",
       "      <td>highwaist short wash stretch denim zip fli but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           prod_name  \\\n",
       "1116957                Seb overshirt   \n",
       "81117                        Jan tee   \n",
       "760759       Orlando padded soft bra   \n",
       "943975             Luna skinny 5 pkt   \n",
       "979649                  ZEBRA CF TVP   \n",
       "401968              CALLISTO ski jkt   \n",
       "346390     ESSENTIAL FIONA LACE TANK   \n",
       "465349   Simple as That Triangle Top   \n",
       "1143228            Ozzy Denim Shorts   \n",
       "1015978              Shorts HW Pixie   \n",
       "\n",
       "                                         clean_detail_desc  \n",
       "1116957  overs shirt jacket wash cotton denim collar bu...  \n",
       "81117    tshirt pattern cotton jersey round necklin che...  \n",
       "760759   soft nonwir bra lace adjust strap cup remov in...  \n",
       "943975   pocket jean wash superstretch denim regular wa...  \n",
       "979649   top lightweight sweatshirt fabric drop shoulde...  \n",
       "401968   pad ski jacket windproof waterrepel breathabl ...  \n",
       "346390   fit top soft rib cotton jersey vneck lace trim...  \n",
       "465349   line nonwir triangl bikini top wide hem narrow...  \n",
       "1143228  highwaist short superstretch twill back pocket...  \n",
       "1015978  highwaist short wash stretch denim zip fli but...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "13c027f8-88fe-4ca2-af9a-657d5e735dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"Denim Jacket\", \"Rounk Neck Tshirt\" , \"padded soft bra\", \"denim jeans\", \"Sweatshirt\", \"Windproof Jacket\", \"Top\" , \"triangl bikini\",\"denim shorts\", \"shorts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a8634-46c9-4f11-9dbd-3a768caa51eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2bd09230-0f60-4eba-b7a8-712771410f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6370903849601746\n",
      "0.7032435536384583\n",
      "0.37777626514434814\n",
      "0.5852794051170349\n",
      "0.9826638586819172\n",
      "0.6709148585796356\n",
      "0.912772923707962\n",
      "0.6733211278915405\n",
      "0.7004756927490234\n",
      "0.742926687002182\n"
     ]
    }
   ],
   "source": [
    "## this function measure the spatical distace between product description and product name. \n",
    "## the smaller the distance the more similar is the graph\n",
    "sim = []\n",
    "for i,j in zip(clean_data , prod_name):\n",
    "    s1_afv = avg_feature_vector(i , model= embeddings_index, num_features=300 )\n",
    "    s2_afv = avg_feature_vector(j , model= embeddings_index, num_features=300 )\n",
    "    cos = distance.cosine(s1_afv, s2_afv)\n",
    "    print(cos)\n",
    "    sim.append(cos)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5f36ba92-b529-4cc4-976b-8024b50b5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6336083114147186\n",
      "0.5499168932437897\n",
      "0.31116408109664917\n",
      "0.3403424620628357\n",
      "0.68471759557724\n",
      "0.591669112443924\n",
      "0.7376987040042877\n",
      "0.6035303473472595\n",
      "0.42207491397857666\n",
      "0.5469109416007996\n"
     ]
    }
   ],
   "source": [
    "## this function measure the spatical distace between product description and product name. \n",
    "## the smaller the distance the more similar is the graph\n",
    "query_sim = []\n",
    "for i,j in zip(clean_data , query):\n",
    "    s1_afv = avg_feature_vector(i , model= embeddings_index, num_features=300 )\n",
    "    s2_afv = avg_feature_vector(j , model= embeddings_index, num_features=300 )\n",
    "    cos = distance.cosine(s1_afv, s2_afv)\n",
    "    print(cos)\n",
    "    query_sim.append(cos)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772ad3d-9b9a-44d6-ae25-a633dec38521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61697b59-14b8-4bec-b945-08ccdfefb73f",
   "metadata": {},
   "source": [
    "# Bert Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ebae1-7e19-4d02-82c8-6f896906ed27",
   "metadata": {},
   "source": [
    "### Simple Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "030a20da-ebbf-4f5a-8cc7-cfd1658facbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326d9797-aeed-40f2-b0a3-2e09ee8c0bf5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dhrsingh\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dhrsingh\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dhrsingh\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dhrsingh\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.9.30)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\dhrsingh\\appdata\\roaming\\python\\python39\\site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dhrsingh\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120751 sha256=c4254dfdd1b37b33018f44d962fc4858ad7b2fc8b26fabde070d043e7b31cc6c\n",
      "  Stored in directory: c:\\users\\dhrsingh\\appdata\\local\\pip\\cache\\wheels\\2b\\11\\3b\\32a18fb9f2253b25d3d1a06f0a84e2d516e7efa19c8c71a283\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: torch, tokenizers, huggingface-hub, transformers, torchvision, sentencepiece, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.7.0 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.12.1 torch-1.11.0 torchvision-0.12.0 transformers-4.19.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "27f71093-a2e4-4a4f-8e5c-9a6e6f04a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8e8695df-e0ac-4f4f-afbe-b14814e4288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_sentence_embeddings = model.encode(clean_data)\n",
    "prod_name_embeddings = model.encode(prod_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2f5234dd-3b73-40a2-96cb-47661bc4fb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 768)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "67fc5720-ba8d-4c7a-9b3f-3b6b96a98ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 768)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_name_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0db525-bd5f-4550-8d7f-7e8ea93cf5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6cb4470e-35f7-4af4-861a-c446a383f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "248b92cd-d630-4c22-8152-f464ffd05b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5291747450828552\n",
      "0.774872362613678\n",
      "0.38676708936691284\n",
      "0.706072986125946\n",
      "0.673152506351471\n",
      "0.5088545083999634\n",
      "0.2938309907913208\n",
      "0.5849405825138092\n",
      "0.33392322063446045\n",
      "0.4877750277519226\n"
     ]
    }
   ],
   "source": [
    "## this function measure the spatical distace between product description and product name. \n",
    "## the smaller the distance the more similar is the graph\n",
    "sbert_sim = []\n",
    "for i,j in zip(clean_data_sentence_embeddings, prod_name_embeddings):\n",
    "    s1_afv = i\n",
    "    s2_afv = j\n",
    "    cos = distance.cosine(s1_afv, s2_afv)\n",
    "    print(cos)\n",
    "    sbert_sim.append(cos)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8ee0ec8e-27cb-4049-b390-f9fcc3b993d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48398202657699585\n",
      "0.33558523654937744\n",
      "0.37731319665908813\n",
      "0.387798547744751\n",
      "0.389896035194397\n",
      "0.6278940141201019\n",
      "0.6838354766368866\n",
      "0.2952868938446045\n",
      "0.38006848096847534\n",
      "0.5320334434509277\n"
     ]
    }
   ],
   "source": [
    "## this function measure the spatical distace between product description and product name. \n",
    "## the smaller the distance the more similar is the graph\n",
    "query_sbert_sim = []\n",
    "for i,j in zip(clean_data_sentence_embeddings, model.encode(query)):\n",
    "    s1_afv = i\n",
    "    s2_afv = j\n",
    "    cos = distance.cosine(s1_afv, s2_afv)\n",
    "    print(cos)\n",
    "    query_sbert_sim.append(cos)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcae0e8-e892-4fce-88f4-0b5a2b76265b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95d34c15-7608-49c3-b1e0-b0a4c455344f",
   "metadata": {},
   "source": [
    "# Bert Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cea754-7f3b-4055-b703-fd14a1ebcab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5734ad99-6c78-4057-9ba4-6e07ad0e02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ba2727e8-227d-43f2-be31-8700c246966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6cec304e-aafc-416b-b2d5-289c1534fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT(sentences):\n",
    "    \n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "    \n",
    "    # initialize dictionary to store tokenized sentences\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # encode each sentence and append to dictionary\n",
    "        new_tokens = tokenizer.encode_plus(sentence, max_length=500,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "        \n",
    "\n",
    "    # reformat list of tensors into single tensor\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    \n",
    "    outputs = model(**tokens)\n",
    "    outputs.keys()\n",
    "    \n",
    "    embeddings = outputs.last_hidden_state\n",
    "    embeddings\n",
    "    \n",
    "    embeddings.shape\n",
    "    \n",
    "    attention_mask = tokens['attention_mask']\n",
    "    attention_mask.shape\n",
    "    \n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    mask.shape\n",
    "\n",
    "    \n",
    "    masked_embeddings = embeddings * mask\n",
    "    masked_embeddings\n",
    "    \n",
    "    summed = torch.sum(masked_embeddings, 1)\n",
    "    summed.shape\n",
    "    \n",
    "    summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    summed_mask.shape\n",
    "    \n",
    "    mean_pooled = summed / summed_mask\n",
    "    \n",
    "    return mean_pooled\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ddfcfa70-9e84-4c4c-904a-4a98886efb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleantext\n",
    "clean_prod_name = []\n",
    "for i in prod_name:\n",
    "    clean_prod_name.append(cleantext.clean(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ea67ec40-ee13-4ada-afbf-e28cf5ac087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_name = clean_prod_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fd3e4ba8-e99b-4d53-bf64-db8d56bb8d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['penni strap top',\n",
       " 'emi linen short',\n",
       " 'ned nasa',\n",
       " 'essenti sign boat neck',\n",
       " 'brit babi tee',\n",
       " 'new pluto dress',\n",
       " 'carri p brazilian',\n",
       " 'kelli strapless sofia pk',\n",
       " 'primo slack',\n",
       " 'bristol']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e6761982-0bb2-4325-a01e-77b871e3d07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 768)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "41b051c1-1765-4424-af49-e29cfba584c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denim Jacket\n",
      "\n",
      "Rounk Neck Tshirt\n",
      "\n",
      "padded soft bra\n",
      "\n",
      "denim jeans\n",
      "\n",
      "Sweatshirt\n",
      "\n",
      "Windproof Jacket\n",
      "\n",
      "Top\n",
      "\n",
      "triangl bikini\n",
      "\n",
      "denim shorts\n",
      "\n",
      "shorts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_name_embedding = []\n",
    "for i in query:\n",
    "    print(i)\n",
    "    query_name_embedding.append(BERT([i]).detach().numpy()[0])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3a9d1c6a-014f-4b88-87ba-30f6e536c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seb overshirt\n",
      "\n",
      "Jan tee\n",
      "\n",
      "Orlando padded soft bra\n",
      "\n",
      "Luna skinny 5 pkt\n",
      "\n",
      "ZEBRA CF TVP\n",
      "\n",
      "CALLISTO ski jkt\n",
      "\n",
      "ESSENTIAL FIONA LACE TANK\n",
      "\n",
      "Simple as That Triangle Top\n",
      "\n",
      "Ozzy Denim Shorts\n",
      "\n",
      "Shorts HW Pixie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod_name_embedding = []\n",
    "for i in prod_name:\n",
    "    print(i)\n",
    "    prod_name_embedding.append(BERT([i]).detach().numpy()[0])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "89822f43-dc65-4fab-85d8-b51fa8355255",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embedding = BERT(\"clean_data\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9892f2ef-cb94-4681-8668-c558259023b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_name_embedding = BERT(\"prod_name\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "38cafef5-aff3-45fd-b0e6-26151355f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_name_embedding = BERT(\"query\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "00423a97-3033-4c69-a086-493da9a0d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39815521240234375\n",
      "0.31475579738616943\n",
      "0.6040824353694916\n",
      "0.5813363194465637\n",
      "0.39055687189102173\n",
      "0.567454606294632\n",
      "0.5486803948879242\n",
      "0.4145025610923767\n",
      "0.5293334722518921\n",
      "0.5735144317150116\n"
     ]
    }
   ],
   "source": [
    "## this function measure the spatical distace between product description and product name. \n",
    "## the smaller the distance the more similar is the graph\n",
    "Bert_sim = []\n",
    "j = 0\n",
    "for i,j in zip(description_embedding, prod_name_embedding):\n",
    "    s1_afv = i\n",
    "    s2_afv = j\n",
    "    cos = distance.cosine(s1_afv, s2_afv)\n",
    "    print(cos)\n",
    "    Bert_sim.append(cos)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "06e287e7-0dbd-4083-a010-3958ea1aa610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5102702081203461\n",
      "0.47770261764526367\n",
      "0.5390638113021851\n",
      "0.5125288665294647\n",
      "0.27759867906570435\n",
      "0.5872719585895538\n",
      "0.15944403409957886\n",
      "0.49699848890304565\n",
      "0.5027430951595306\n",
      "0.2733139991760254\n"
     ]
    }
   ],
   "source": [
    "## this function measure the spatical distace between product description and product name. \n",
    "## the smaller the distance the more similar is the graph\n",
    "query_Bert_sim = []\n",
    "j = 0\n",
    "for i,j in zip(description_embedding, query_name_embedding):\n",
    "    s1_afv = i\n",
    "    s2_afv = j\n",
    "    cos = distance.cosine(s1_afv, s2_afv)\n",
    "    print(cos)\n",
    "    query_Bert_sim.append(cos)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7abe0-538b-49c9-9bce-893f4220fee7",
   "metadata": {},
   "source": [
    "# FuzzyWuzzy Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c9d88174-06b7-48ec-b3ca-d069403c65c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "70115c59-25e7-4af0-810e-43aea0c27e1f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting python-Levenshtein\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dhrsingh\\anaconda3\\lib\\site-packages (from python-Levenshtein) (61.2.0)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\dhrsingh\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\dhrsingh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lm5xls0t\\\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\dhrsingh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lm5xls0t\\\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\dhrsingh\\AppData\\Local\\Temp\\pip-wheel-x__d1ox9'\n",
      "       cwd: C:\\Users\\dhrsingh\\AppData\\Local\\Temp\\pip-install-lm5xls0t\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\n",
      "  Complete output (28 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\StringMatcher.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\__init__.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  running egg_info\n",
      "  writing python_Levenshtein.egg-info\\PKG-INFO\n",
      "  writing dependency_links to python_Levenshtein.egg-info\\dependency_links.txt\n",
      "  deleting python_Levenshtein.egg-info\\entry_points.txt\n",
      "  writing namespace_packages to python_Levenshtein.egg-info\\namespace_packages.txt\n",
      "  writing requirements to python_Levenshtein.egg-info\\requires.txt\n",
      "  writing top-level names to python_Levenshtein.egg-info\\top_level.txt\n",
      "  reading manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for python-Levenshtein (setup.py): started\n",
      "  Building wheel for python-Levenshtein (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for python-Levenshtein\n",
      "Failed to build python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "    Running setup.py install for python-Levenshtein: started\n",
      "    Running setup.py install for python-Levenshtein: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*so' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.project' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.pydevproject' found anywhere in distribution\n",
      "  adding license file 'COPYING'\n",
      "  writing manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "  copying Levenshtein\\_levenshtein.c -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\_levenshtein.h -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  running build_ext\n",
      "  building 'Levenshtein._levenshtein' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for python-Levenshtein\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\dhrsingh\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\dhrsingh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lm5xls0t\\\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\dhrsingh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lm5xls0t\\\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\dhrsingh\\AppData\\Local\\Temp\\pip-record-5zho_7n1\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\dhrsingh\\Anaconda3\\Include\\python-Levenshtein'\n",
      "         cwd: C:\\Users\\dhrsingh\\AppData\\Local\\Temp\\pip-install-lm5xls0t\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\n",
      "    Complete output (29 lines):\n",
      "    running install\n",
      "    C:\\Users\\dhrsingh\\Anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.9\n",
      "    creating build\\lib.win-amd64-3.9\\Levenshtein\n",
      "    copying Levenshtein\\StringMatcher.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "    copying Levenshtein\\__init__.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "    running egg_info\n",
      "    writing python_Levenshtein.egg-info\\PKG-INFO\n",
      "    writing dependency_links to python_Levenshtein.egg-info\\dependency_links.txt\n",
      "    writing namespace_packages to python_Levenshtein.egg-info\\namespace_packages.txt\n",
      "    writing requirements to python_Levenshtein.egg-info\\requires.txt\n",
      "    writing top-level names to python_Levenshtein.egg-info\\top_level.txt\n",
      "    reading manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*so' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.project' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.pydevproject' found anywhere in distribution\n",
      "    adding license file 'COPYING'\n",
      "    writing manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "    copying Levenshtein\\_levenshtein.c -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "    copying Levenshtein\\_levenshtein.h -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "    running build_ext\n",
      "    building 'Levenshtein._levenshtein' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\dhrsingh\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\dhrsingh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lm5xls0t\\\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\dhrsingh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-lm5xls0t\\\\python-levenshtein_18486c8811cf47429b4a2e1f1f18aff3\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\dhrsingh\\AppData\\Local\\Temp\\pip-record-5zho_7n1\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\dhrsingh\\Anaconda3\\Include\\python-Levenshtein' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e4636bea-fce2-4b37-97d2-6e61871d5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cfeaced0-b26b-4dbd-aaa7-e3e15ae1061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzywuzzy_sim = []\n",
    "query_fuzzywuzzy_sim = []\n",
    "\n",
    "for i,j,k in zip(clean_data, prod_name, query):\n",
    "    fuzzywuzzy_sim.append(fuzz.ratio( i , j )*0.01)\n",
    "    query_fuzzywuzzy_sim.append(fuzz.ratio( i , k )*0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0fcbe7de-027a-4c0b-9ce8-85a79e5b4ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17, 0.17, 0.04, 0.06, 0.32, 0.1, 0.15, 0.18, 0.16, 0.09]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzywuzzy_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "fbcb0015-c26c-4e8d-92bf-35420d31d900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09, 0.14, 0.12, 0.21, 0.21, 0.08, 0.05, 0.18, 0.21, 0.11]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_fuzzywuzzy_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3caf0888-f01b-45a9-8bc9-df43bf17a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.loc[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3302135f-6cca-4d02-9603-0a83cb3caa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"Query\"] = query\n",
    "result[\"Word2Vec Score\"] = sim\n",
    "result[\"Simple Bert Score\"] = sbert_sim\n",
    "result[\"Bert Score\"] = Bert_sim\n",
    "result[\"FuzzyWuzzy Score\"] = fuzzywuzzy_sim\n",
    "result[\"Query Word2Vec Score\"] = query_sim\n",
    "result[\"Query Simple Bert Score\"] = query_sbert_sim\n",
    "result[\"Query Bert Score\"] = query_Bert_sim\n",
    "result[\"Query FuzzyWuzzy Score\"] = query_fuzzywuzzy_sim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f1ec00f1-a93f-4d97-99eb-eb21f30e5242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>clean_detail_desc</th>\n",
       "      <th>Query</th>\n",
       "      <th>Word2Vec Score</th>\n",
       "      <th>Simple Bert Score</th>\n",
       "      <th>Bert Score</th>\n",
       "      <th>FuzzyWuzzy Score</th>\n",
       "      <th>Query Word2Vec Score</th>\n",
       "      <th>Query Simple Bert Score</th>\n",
       "      <th>Query Bert Score</th>\n",
       "      <th>Query FuzzyWuzzy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116957</th>\n",
       "      <td>Seb overshirt</td>\n",
       "      <td>overs shirt jacket wash cotton denim collar bu...</td>\n",
       "      <td>Denim Jacket</td>\n",
       "      <td>0.637090</td>\n",
       "      <td>0.529175</td>\n",
       "      <td>0.398155</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.633608</td>\n",
       "      <td>0.483982</td>\n",
       "      <td>0.510270</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81117</th>\n",
       "      <td>Jan tee</td>\n",
       "      <td>tshirt pattern cotton jersey round necklin che...</td>\n",
       "      <td>Rounk Neck Tshirt</td>\n",
       "      <td>0.703244</td>\n",
       "      <td>0.774872</td>\n",
       "      <td>0.314756</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.549917</td>\n",
       "      <td>0.335585</td>\n",
       "      <td>0.477703</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760759</th>\n",
       "      <td>Orlando padded soft bra</td>\n",
       "      <td>soft nonwir bra lace adjust strap cup remov in...</td>\n",
       "      <td>padded soft bra</td>\n",
       "      <td>0.377776</td>\n",
       "      <td>0.386767</td>\n",
       "      <td>0.604082</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.311164</td>\n",
       "      <td>0.377313</td>\n",
       "      <td>0.539064</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943975</th>\n",
       "      <td>Luna skinny 5 pkt</td>\n",
       "      <td>pocket jean wash superstretch denim regular wa...</td>\n",
       "      <td>denim jeans</td>\n",
       "      <td>0.585279</td>\n",
       "      <td>0.706073</td>\n",
       "      <td>0.581336</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.340342</td>\n",
       "      <td>0.387799</td>\n",
       "      <td>0.512529</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979649</th>\n",
       "      <td>ZEBRA CF TVP</td>\n",
       "      <td>top lightweight sweatshirt fabric drop shoulde...</td>\n",
       "      <td>Sweatshirt</td>\n",
       "      <td>0.982664</td>\n",
       "      <td>0.673153</td>\n",
       "      <td>0.390557</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.684718</td>\n",
       "      <td>0.389896</td>\n",
       "      <td>0.277599</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401968</th>\n",
       "      <td>CALLISTO ski jkt</td>\n",
       "      <td>pad ski jacket windproof waterrepel breathabl ...</td>\n",
       "      <td>Windproof Jacket</td>\n",
       "      <td>0.670915</td>\n",
       "      <td>0.508855</td>\n",
       "      <td>0.567455</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.591669</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.587272</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346390</th>\n",
       "      <td>ESSENTIAL FIONA LACE TANK</td>\n",
       "      <td>fit top soft rib cotton jersey vneck lace trim...</td>\n",
       "      <td>Top</td>\n",
       "      <td>0.912773</td>\n",
       "      <td>0.293831</td>\n",
       "      <td>0.548680</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.737699</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>0.159444</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465349</th>\n",
       "      <td>Simple as That Triangle Top</td>\n",
       "      <td>line nonwir triangl bikini top wide hem narrow...</td>\n",
       "      <td>triangl bikini</td>\n",
       "      <td>0.673321</td>\n",
       "      <td>0.584941</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.603530</td>\n",
       "      <td>0.295287</td>\n",
       "      <td>0.496998</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143228</th>\n",
       "      <td>Ozzy Denim Shorts</td>\n",
       "      <td>highwaist short superstretch twill back pocket...</td>\n",
       "      <td>denim shorts</td>\n",
       "      <td>0.700476</td>\n",
       "      <td>0.333923</td>\n",
       "      <td>0.529333</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.422075</td>\n",
       "      <td>0.380068</td>\n",
       "      <td>0.502743</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015978</th>\n",
       "      <td>Shorts HW Pixie</td>\n",
       "      <td>highwaist short wash stretch denim zip fli but...</td>\n",
       "      <td>shorts</td>\n",
       "      <td>0.742927</td>\n",
       "      <td>0.487775</td>\n",
       "      <td>0.573514</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.546911</td>\n",
       "      <td>0.532033</td>\n",
       "      <td>0.273314</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           prod_name  \\\n",
       "1116957                Seb overshirt   \n",
       "81117                        Jan tee   \n",
       "760759       Orlando padded soft bra   \n",
       "943975             Luna skinny 5 pkt   \n",
       "979649                  ZEBRA CF TVP   \n",
       "401968              CALLISTO ski jkt   \n",
       "346390     ESSENTIAL FIONA LACE TANK   \n",
       "465349   Simple as That Triangle Top   \n",
       "1143228            Ozzy Denim Shorts   \n",
       "1015978              Shorts HW Pixie   \n",
       "\n",
       "                                         clean_detail_desc              Query  \\\n",
       "1116957  overs shirt jacket wash cotton denim collar bu...       Denim Jacket   \n",
       "81117    tshirt pattern cotton jersey round necklin che...  Rounk Neck Tshirt   \n",
       "760759   soft nonwir bra lace adjust strap cup remov in...    padded soft bra   \n",
       "943975   pocket jean wash superstretch denim regular wa...        denim jeans   \n",
       "979649   top lightweight sweatshirt fabric drop shoulde...         Sweatshirt   \n",
       "401968   pad ski jacket windproof waterrepel breathabl ...   Windproof Jacket   \n",
       "346390   fit top soft rib cotton jersey vneck lace trim...                Top   \n",
       "465349   line nonwir triangl bikini top wide hem narrow...     triangl bikini   \n",
       "1143228  highwaist short superstretch twill back pocket...       denim shorts   \n",
       "1015978  highwaist short wash stretch denim zip fli but...             shorts   \n",
       "\n",
       "         Word2Vec Score  Simple Bert Score  Bert Score  FuzzyWuzzy Score  \\\n",
       "1116957        0.637090           0.529175    0.398155              0.11   \n",
       "81117          0.703244           0.774872    0.314756              0.13   \n",
       "760759         0.377776           0.386767    0.604082              0.12   \n",
       "943975         0.585279           0.706073    0.581336              0.17   \n",
       "979649         0.982664           0.673153    0.390557              0.05   \n",
       "401968         0.670915           0.508855    0.567455              0.05   \n",
       "346390         0.912773           0.293831    0.548680              0.06   \n",
       "465349         0.673321           0.584941    0.414503              0.16   \n",
       "1143228        0.700476           0.333923    0.529333              0.17   \n",
       "1015978        0.742927           0.487775    0.573514              0.12   \n",
       "\n",
       "         Query Word2Vec Score  Query Simple Bert Score  Query Bert Score  \\\n",
       "1116957              0.633608                 0.483982          0.510270   \n",
       "81117                0.549917                 0.335585          0.477703   \n",
       "760759               0.311164                 0.377313          0.539064   \n",
       "943975               0.340342                 0.387799          0.512529   \n",
       "979649               0.684718                 0.389896          0.277599   \n",
       "401968               0.591669                 0.627894          0.587272   \n",
       "346390               0.737699                 0.683835          0.159444   \n",
       "465349               0.603530                 0.295287          0.496998   \n",
       "1143228              0.422075                 0.380068          0.502743   \n",
       "1015978              0.546911                 0.532033          0.273314   \n",
       "\n",
       "         Query FuzzyWuzzy Score  \n",
       "1116957                    0.09  \n",
       "81117                      0.14  \n",
       "760759                     0.12  \n",
       "943975                     0.21  \n",
       "979649                     0.21  \n",
       "401968                     0.08  \n",
       "346390                     0.05  \n",
       "465349                     0.18  \n",
       "1143228                    0.21  \n",
       "1015978                    0.11  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f2704f8a-f4c1-4989-8a97-306726587d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"Embedding Model.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
