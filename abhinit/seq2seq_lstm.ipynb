{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d775cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6b2b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strap top</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strap top</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>Off White</td>\n",
       "      <td>Dusty Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           prod_name product_type_name  product_group_name  \\\n",
       "0          Strap top          Vest top  Garment Upper body   \n",
       "1          Strap top          Vest top  Garment Upper body   \n",
       "2      Strap top (1)          Vest top  Garment Upper body   \n",
       "3  OP T-shirt (Idro)               Bra           Underwear   \n",
       "4  OP T-shirt (Idro)               Bra           Underwear   \n",
       "\n",
       "  graphical_appearance_name colour_group_name perceived_colour_value_name  \n",
       "0                     Solid             Black                        Dark  \n",
       "1                     Solid             White                       Light  \n",
       "2                    Stripe         Off White                 Dusty Light  \n",
       "3                     Solid             Black                        Dark  \n",
       "4                     Solid             White                       Light  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading the articles dataset\n",
    "articles=pd.read_csv('articles.csv',usecols=['prod_name','product_type_name','product_group_name',\n",
    "                                            'graphical_appearance_name','colour_group_name',\n",
    "                                             'perceived_colour_value_name'])\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8aafea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strap top</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strap top</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>Off White</td>\n",
       "      <td>Dusty Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           prod_name product_type_name product_group_name  \\\n",
       "0          Strap top                 0                  0   \n",
       "1          Strap top                 0                  0   \n",
       "2      Strap top (1)                 0                  0   \n",
       "3  OP T-shirt (Idro)                 1                  1   \n",
       "4  OP T-shirt (Idro)                 1                  1   \n",
       "\n",
       "  graphical_appearance_name colour_group_name perceived_colour_value_name  \n",
       "0                     Solid             Black                        Dark  \n",
       "1                     Solid             White                       Light  \n",
       "2                    Stripe         Off White                 Dusty Light  \n",
       "3                     Solid             Black                        Dark  \n",
       "4                     Solid             White                       Light  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating dictionaries for categories in 'product_group_name' and 'product_type_name'\n",
    "type_dict={v:k for k,v in dict(enumerate(articles['product_type_name'].unique())).items()}\n",
    "group_dict={v:k for k,v in dict(enumerate(articles['product_group_name'].unique())).items()}\n",
    "\n",
    "##creating the reverse of these dictionaries for final decoding\n",
    "reverse_type_dict={v:k for k,v in type_dict.items()}\n",
    "reverse_group_dict={v:k for k,v in group_dict.items()}\n",
    "\n",
    "##replacing values in articles with placeholders\n",
    "articles['product_type_name']=articles['product_type_name'].apply(lambda x:str(type_dict[x]))\n",
    "articles['product_group_name']=articles['product_group_name'].apply(lambda x:str(group_dict[x]))\n",
    "\n",
    "##checking the head of the dataset\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e9350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6046d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(ordered_cols):\n",
    "    df=articles\n",
    "    df['query']=df['prod_name']\n",
    "    ##adding attributes to the product name to generate queries\n",
    "    ##reversing ordered_cols\n",
    "    ordered_cols.reverse()\n",
    "    for col in ordered_cols:\n",
    "        df['query']=df[col]+' '+df['query']\n",
    "    ##combining product_group_name and product_type_name into a single output column\n",
    "    df['output']=df['product_group_name']+' '+df['product_type_name']\n",
    "    ##reduce to the input and output columns\n",
    "    df=df[['query','output']]\n",
    "    ##reducing all text to lowercase\n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].apply(lambda x:x.lower())\n",
    "    ##return the created dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583a6c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_38792\\3479466943.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_38792\\3479466943.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_38792\\3479466943.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_38792\\3479466943.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_38792\\3479466943.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_38792\\3479466943.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].apply(lambda x:x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solid strap top</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solid strap top</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stripe strap top (1)</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solid op t-shirt (idro)</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solid op t-shirt (idro)</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     query output\n",
       "0          solid strap top    0 0\n",
       "1          solid strap top    0 0\n",
       "2     stripe strap top (1)    0 0\n",
       "3  solid op t-shirt (idro)    1 1\n",
       "4  solid op t-shirt (idro)    1 1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating combinations\n",
    "set_1=make_df(['graphical_appearance_name'])\n",
    "set_2=make_df(['colour_group_name'])\n",
    "set_3=make_df(['perceived_colour_value_name'])\n",
    "set_4=make_df(['graphical_appearance_name','colour_group_name'])\n",
    "set_5=make_df(['perceived_colour_value_name','colour_group_name'])\n",
    "set_6=make_df(['graphical_appearance_name','perceived_colour_value_name','colour_group_name'])\n",
    "\n",
    "##deleting the articles dataset\n",
    "del(articles)\n",
    "\n",
    "##concatenating all dataframes into a single one\n",
    "data=pd.concat([set_1,set_2,set_3,set_4,set_5,set_6])\n",
    "\n",
    "#resetting index\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index',axis=1,inplace=True)\n",
    "\n",
    "##deleting all the sets\n",
    "del(set_1,set_2,set_3,set_4,set_5,set_6)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d983f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##USING ENCODER-DECODER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a366e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##adding 'start_ ' and ' _end' at the extemities of 'output' so that the decoder knows when the sentence starts and ends\n",
    "data['output']=data['output'].apply(lambda x:'start_ '+x+' _end')\n",
    "\n",
    "##creating vocabularies for both 'query' and 'output'\n",
    "def get_vocab(col):\n",
    "    container=set()\n",
    "    for line in data[col]:\n",
    "        for word in line.split(' '):\n",
    "            if word not in container:\n",
    "                container.add(word)\n",
    "    ##number of tokens for encoder/decoder = number of unique elements in vocab\n",
    "    num_tokens=len(list(container))\n",
    "    ##return vocab and num_tokens\n",
    "    return sorted(list(container)), num_tokens\n",
    "\n",
    "query_vocab,num_encoder_tokens=get_vocab('query')\n",
    "output_vocab,num_decoder_tokens=get_vocab('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34be6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculate the maximum lengths of sentences in 'query' and 'output'\n",
    "max_query_len=max(data['query'].apply(lambda x:len(x.split(' '))))\n",
    "max_output_len=max(data['output'].apply(lambda x:len(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24662412",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_token_index = dict([(word, i) for i, word in enumerate(query_vocab)])\n",
    "output_token_index = dict([(word, i) for i, word in enumerate(output_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6545f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(data['query']), max_query_len),dtype='float32')\n",
    "decoder_input_data = np.zeros((len(data['output']), max_output_len),dtype='float32')\n",
    "decoder_target_data = np.zeros((len(data['output']), max_output_len, num_decoder_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb97cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(data['query'],data['output'])):\n",
    "    for t,word in enumerate(input_text.split(' ')):\n",
    "        encoder_input_data[i,t]=query_token_index[word]\n",
    "    for t,word in enumerate(target_text.split(' ')):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i,t]=output_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i,t-1,output_token_index[word]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e998bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##inmporting libraries for building the model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9cd8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##building the encoder\n",
    "\n",
    "encoder_inputs=Input(shape=(None,)) ##input layer for the encoder\n",
    "enx=Embedding(num_encoder_tokens, 64)(encoder_inputs) ##converts integers to embeddings\n",
    "encoder=LSTM(64,return_state=True) ##encoder units for the seq2seq model\n",
    "encoder_outputs,state_h,state_c=encoder(enx) ##extracting states using the LSTM encoder units\n",
    "##we discard `encoder_outputs` and only keep the states\n",
    "##'encoder_outputs' are not required as they are neither inferred nor used by the decoder\n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436a9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##building the decoder\n",
    "\n",
    "decoder_inputs=Input(shape=(None,)) ##input layer for the decoder\n",
    "dex=Embedding(num_decoder_tokens,64)\n",
    "final_dex=dex(decoder_inputs)\n",
    "decoder=LSTM(64,return_state=True,return_sequences=True)\n",
    "decoder_outputs,_,_=decoder(final_dex,initial_state=encoder_states)\n",
    "decoder_dense=Dense(num_decoder_tokens,activation='softmax') ##probability output for the decoder outputs\n",
    "decoder_outputs=decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ee91e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 64)     905088      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 64)     8512        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64),         33024       ['embedding[0][0]']              \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['embedding_1[0][0]',            \n",
      "                                 (None, 64),                      'lstm[0][1]',                   \n",
      "                                 (None, 64)]                      'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 133)    8645        ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 988,293\n",
      "Trainable params: 988,293\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##compiling the model\n",
    "\n",
    "model = Model([encoder_inputs,decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc4a227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18800/18800 [==============================] - 196s 10ms/step - loss: 0.3029 - acc: 0.9142 - val_loss: 0.1851 - val_acc: 0.9544\n",
      "Epoch 2/10\n",
      "18800/18800 [==============================] - 195s 10ms/step - loss: 0.1379 - acc: 0.9620 - val_loss: 0.1442 - val_acc: 0.9650\n",
      "Epoch 3/10\n",
      "18800/18800 [==============================] - 192s 10ms/step - loss: 0.1089 - acc: 0.9715 - val_loss: 0.1300 - val_acc: 0.9666\n",
      "Epoch 4/10\n",
      "18800/18800 [==============================] - 194s 10ms/step - loss: 0.0917 - acc: 0.9761 - val_loss: 0.1077 - val_acc: 0.9728\n",
      "Epoch 5/10\n",
      "18800/18800 [==============================] - 196s 10ms/step - loss: 0.0814 - acc: 0.9790 - val_loss: 0.0932 - val_acc: 0.9763\n",
      "Epoch 6/10\n",
      "18800/18800 [==============================] - 204s 11ms/step - loss: 0.0737 - acc: 0.9808 - val_loss: 0.0878 - val_acc: 0.9778\n",
      "Epoch 7/10\n",
      "18800/18800 [==============================] - 188s 10ms/step - loss: 0.0678 - acc: 0.9822 - val_loss: 0.0786 - val_acc: 0.9796\n",
      "Epoch 8/10\n",
      "18800/18800 [==============================] - 190s 10ms/step - loss: 0.0627 - acc: 0.9835 - val_loss: 0.0717 - val_acc: 0.9811\n",
      "Epoch 9/10\n",
      "18800/18800 [==============================] - 194s 10ms/step - loss: 0.0590 - acc: 0.9845 - val_loss: 0.0735 - val_acc: 0.9807\n",
      "Epoch 10/10\n",
      "18800/18800 [==============================] - 202s 11ms/step - loss: 0.0552 - acc: 0.9855 - val_loss: 0.0697 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240fe906f10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef496ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_lstm\\assets\n"
     ]
    }
   ],
   "source": [
    "##saving the trained model\n",
    "model.save('seq2seq_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "829dfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##decoding sequences back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a06413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 64)          905088    \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 64),              33024     \n",
      "                              (None, 64),                        \n",
      "                              (None, 64)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 938,112\n",
      "Trainable params: 938,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##creating encoder model\n",
    "encoder_model=Model(encoder_inputs,encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2353cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 64)     8512        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['embedding_1[1][0]',            \n",
      "                                 (None, 64),                      'input_3[0][0]',                \n",
      "                                 (None, 64)]                      'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 133)    8645        ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,181\n",
      "Trainable params: 50,181\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##creating decoder model\n",
    "decoder_state_input_h=Input(shape=(64,)) ##takes state_h values from the encoder model\n",
    "decoder_state_input_c=Input(shape=(64,)) ##takes state_c values from the encoder model\n",
    "decoder_states_inputs=[decoder_state_input_h,decoder_state_input_c]\n",
    "\n",
    "final_dex2=dex(decoder_inputs) ##embedding the input received by the decoder\n",
    "\n",
    "decoder_outputs2,state_h2,state_c2=decoder(final_dex2,initial_state=decoder_states_inputs)\n",
    "decoder_states2=[state_h2,state_c2]\n",
    "decoder_outputs2=decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model=Model(([decoder_inputs],decoder_states_inputs),([decoder_outputs2],decoder_states2))\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b6279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "943418ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating reverse token dictionaries\n",
    "reverse_query_token_index={v:k for k,v in query_token_index.items()}\n",
    "reverse_output_token_index={v:k for k,v in output_token_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b35e0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to get encoder input for a sentence\n",
    "def get_encoder_input():\n",
    "    seq=input().split(' ')\n",
    "    encoder_input_data=np.zeros(max_query_len)\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] not in query_token_index.keys():\n",
    "            encoder_input_data[i]=0\n",
    "        else:\n",
    "            encoder_input_data[i]=query_token_index[seq[i]]\n",
    "    return np.array([encoder_input_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a4b51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to decode sequences\n",
    "def decode_seq():\n",
    "    ##taking input sequence from the user\n",
    "    input_seq=get_encoder_input()\n",
    "    ##encoder_input_seq=np.zeros(1,max_query_len),dtype='float32')\n",
    "    #encode the input as state vectors.\n",
    "    states_value=encoder_model.predict(input_seq)\n",
    "    #generate empty target sequence of length 1\n",
    "    target_seq=np.zeros((1,1))\n",
    "    #populate the first character of target sequence with the start character.\n",
    "    target_seq[0,0]=output_token_index['start_']\n",
    "    #sampling loop for a batch of sequences\n",
    "    #(to simplify, here we assume a batch of size 1).\n",
    "    stop_condition=False\n",
    "    decoded_sentence=''\n",
    "    while not stop_condition:\n",
    "        [output_tokens],_states=decoder_model.predict(([target_seq],states_value))\n",
    "        #sample a token\n",
    "        sampled_token_index=np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char=reverse_output_token_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "        \n",
    "        #exit condition: either hit max length\n",
    "        #or find stop character\n",
    "        if (sampled_char == '_end' or\n",
    "           len(decoded_sentence)>4):\n",
    "            stop_condition=True\n",
    "            \n",
    "        #update the target sequence (of length 1)\n",
    "        target_seq=np.zeros((1,1))\n",
    "        target_seq[0, 0]=sampled_token_index\n",
    "        \n",
    "        #update states\n",
    "        states_value=[_states[0],_states[1]]\n",
    "        \n",
    "    [cat_token,sub_token]=decoded_sentence.split(' ')[1:3]\n",
    "    output_dict={'category':reverse_group_dict[int(cat_token)],\n",
    "                'subcategory':reverse_type_dict[int(sub_token)]}\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d1c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solid black shirt men\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Garment Upper body', 'subcategory': 'Shirt'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4251a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denim pants blue\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Garment Lower body', 'subcategory': 'Trousers'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1454a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solid jackets\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Garment Upper body', 'subcategory': 'Sweater'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9cf32c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red dress\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Garment Full body', 'subcategory': 'Dress'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b8510d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt for men\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Garment Upper body', 'subcategory': 'Bodysuit'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dadddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d521d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eebdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d443f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfe837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0072968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb5c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3be987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c339142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b131d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35089828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2be2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d7384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09058830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8db71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e803a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f96b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60c0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e5556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e947b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d634b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e78285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb12b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd998e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef9c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e918db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db94e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e95a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f964eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fa5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384873c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11101cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51eb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9c6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7808b452",
   "metadata": {},
   "source": [
    "##splitting data into train and test sets\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "##creating feature and target sets\n",
    "X=data['query']\n",
    "y=data['output']\n",
    "\n",
    "##instantiating\n",
    "sss=StratifiedShuffleSplit(test_size=0.2,random_state=42)\n",
    "\n",
    "##creating train and test sets\n",
    "train_idx,test_idx=next(sss.split(X,y))\n",
    "X_train,X_test,y_train,y_test=X.iloc[train_idx],X.iloc[test_idx],y.iloc[train_idx],y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64800bce",
   "metadata": {},
   "source": [
    "##tokenizing the text data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "##instantiating and fitting the query tokenizer\n",
    "query_tokenizer=Tokenizer(num_words=100000,lower=True)\n",
    "query_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "##tokeinizng the query\n",
    "X_train=query_tokenizer.texts_to_sequences(X_train)\n",
    "X_test=query_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "##instantiating and fitting the output tokenizer\n",
    "output_tokenizer=Tokenizer(num_words=100000,lower=True)\n",
    "output_tokenizer.fit_on_texts(y_train)\n",
    "\n",
    "##tokeinizng the query\n",
    "y_train=output_tokenizer.texts_to_sequences(y_train)\n",
    "y_test=output_tokenizer.texts_to_sequences(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3de7b",
   "metadata": {},
   "source": [
    "##padding the query and ouput\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "query_length=15 ##max length of query\n",
    "output_length=7 ##max length of output\n",
    "\n",
    "X_train=pad_sequences(X_train,padding='post',maxlen=query_length)\n",
    "X_test=pad_sequences(X_test,padding='post',maxlen=query_length)\n",
    "\n",
    "y_train=pad_sequences(y_train,padding='post',maxlen=output_length)\n",
    "y_test=pad_sequences(y_test,padding='post',maxlen=output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db3345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d464377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a18122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657de4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
