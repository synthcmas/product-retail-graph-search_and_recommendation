{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f349bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f3800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strap top</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strap top</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>Off White</td>\n",
       "      <td>Dusty Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Solid</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           prod_name product_type_name  product_group_name  \\\n",
       "0          Strap top          Vest top  Garment Upper body   \n",
       "1          Strap top          Vest top  Garment Upper body   \n",
       "2      Strap top (1)          Vest top  Garment Upper body   \n",
       "3  OP T-shirt (Idro)               Bra           Underwear   \n",
       "4  OP T-shirt (Idro)               Bra           Underwear   \n",
       "\n",
       "  graphical_appearance_name colour_group_name perceived_colour_value_name  \n",
       "0                     Solid             Black                        Dark  \n",
       "1                     Solid             White                       Light  \n",
       "2                    Stripe         Off White                 Dusty Light  \n",
       "3                     Solid             Black                        Dark  \n",
       "4                     Solid             White                       Light  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles=pd.read_csv('articles.csv',\n",
    "                    usecols=['prod_name','product_type_name','product_group_name','graphical_appearance_name',\n",
    "                              'colour_group_name','perceived_colour_value_name'])\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8372985",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_subcat={}\n",
    "for cat in articles['product_group_name'].unique():\n",
    "    cat_subcat[cat]=list(articles[articles['product_group_name']==cat]['product_type_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffbea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569d1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72505ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining threshold for selecting categories\n",
    "cat_thres=np.mean(articles['product_group_name'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0817cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##selecting categories\n",
    "cats=[cat for cat in articles['product_group_name'].value_counts().index \n",
    "      if (articles['product_group_name'].value_counts()[cat]>cat_thres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc0af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining threshold for selecting subcategories\n",
    "subcat_thres=np.mean(articles['product_type_name'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521abe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##selecting subcategories\n",
    "subcats=[subcat for subcat in articles['product_type_name'].value_counts().index \n",
    "      if (articles['product_type_name'].value_counts()[subcat]>subcat_thres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de6f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_category(cat):\n",
    "    if cat not in cats:\n",
    "        return 'no_category'\n",
    "    else:\n",
    "        return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5aafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_subcategory(subcat):\n",
    "    if subcat not in subcats:\n",
    "        return 'no_subcategory'\n",
    "    else:\n",
    "        return subcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196735d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['product_group_name']=articles['product_group_name'].apply(lambda x:no_category(x))\n",
    "articles['product_type_name']=articles['product_type_name'].apply(lambda x:no_subcategory(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa9bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Garment Upper body    42741\n",
       "Garment Lower body    19812\n",
       "no_category           18539\n",
       "Garment Full body     13292\n",
       "Accessories           11158\n",
       "Name: product_group_name, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['product_group_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e29f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_subcategory       11962\n",
       "Trousers             11169\n",
       "Dress                10362\n",
       "Sweater               9302\n",
       "T-shirt               7904\n",
       "Top                   4155\n",
       "Blouse                3979\n",
       "Jacket                3940\n",
       "Shorts                3939\n",
       "Shirt                 3405\n",
       "Vest top              2991\n",
       "Underwear bottom      2748\n",
       "Skirt                 2696\n",
       "Hoodie                2356\n",
       "Bra                   2212\n",
       "Socks                 1889\n",
       "Leggings/Tights       1878\n",
       "Sneakers              1621\n",
       "Cardigan              1550\n",
       "Hat/beanie            1349\n",
       "Garment Set           1320\n",
       "Swimwear bottom       1307\n",
       "Bag                   1280\n",
       "Earring               1159\n",
       "Jumpsuit/Playsuit     1147\n",
       "Pyjama set            1120\n",
       "Blazer                1110\n",
       "Other accessories     1034\n",
       "Boots                 1028\n",
       "Scarf                 1013\n",
       "Bodysuit               913\n",
       "Hair/alice band        854\n",
       "Bikini top             850\n",
       "Name: product_type_name, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['product_type_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5f0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(ordered_cols):\n",
    "    df=articles\n",
    "    df['input_text']=df['prod_name']\n",
    "    ##adding attributes to the product name to generate queries\n",
    "    ##reversing ordered_cols\n",
    "    ordered_cols.reverse()\n",
    "    for col in ordered_cols:\n",
    "        df['input_text']=df[col]+' '+df['input_text']\n",
    "    ##reduce to the input and output columns\n",
    "    df=df[['input_text','product_group_name','product_type_name']]\n",
    "    ##reducing input text to lowercase\n",
    "    df['input_text']=df['input_text'].apply(lambda x:x.lower())\n",
    "    ##return the created dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcec5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_6688\\2168342493.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['input_text']=df['input_text'].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_6688\\2168342493.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['input_text']=df['input_text'].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_6688\\2168342493.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['input_text']=df['input_text'].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_6688\\2168342493.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['input_text']=df['input_text'].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_6688\\2168342493.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['input_text']=df['input_text'].apply(lambda x:x.lower())\n",
      "C:\\Users\\abhsingh73\\AppData\\Local\\Temp\\ipykernel_6688\\2168342493.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['input_text']=df['input_text'].apply(lambda x:x.lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>product_type_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top solid strap</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Vest top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solid strap top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Vest top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stripe top strap (1)</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Vest top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solid t-shirt op (idro)</td>\n",
       "      <td>no_category</td>\n",
       "      <td>Bra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t-shirt op solid (idro)</td>\n",
       "      <td>no_category</td>\n",
       "      <td>Bra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                input_text  product_group_name product_type_name\n",
       "0          top solid strap  Garment Upper body          Vest top\n",
       "1          solid strap top  Garment Upper body          Vest top\n",
       "2     stripe top strap (1)  Garment Upper body          Vest top\n",
       "3  solid t-shirt op (idro)         no_category               Bra\n",
       "4  t-shirt op solid (idro)         no_category               Bra"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating combinations\n",
    "set_1=make_df(['graphical_appearance_name'])\n",
    "set_2=make_df(['colour_group_name'])\n",
    "set_3=make_df(['perceived_colour_value_name'])\n",
    "set_4=make_df(['graphical_appearance_name','colour_group_name'])\n",
    "set_5=make_df(['perceived_colour_value_name','colour_group_name'])\n",
    "set_6=make_df(['graphical_appearance_name','perceived_colour_value_name','colour_group_name'])\n",
    "\n",
    "##deleting the articles dataset\n",
    "##del(articles)\n",
    "\n",
    "##concatenating all dataframes into a single one\n",
    "data=pd.concat([set_1,set_2,set_3,set_4,set_5,set_6])\n",
    "\n",
    "def jumble_words(sent):\n",
    "    sent_list=sent.split(' ')\n",
    "    np.random.shuffle(sent_list)\n",
    "    return ' '.join(sent_list)\n",
    "\n",
    "data['input_text']=data['input_text'].apply(lambda x:jumble_words(x))\n",
    "\n",
    "#resetting index\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index',axis=1,inplace=True)\n",
    "\n",
    "##deleting all the sets\n",
    "del(set_1,set_2,set_3,set_4,set_5,set_6)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e3c0b7f",
   "metadata": {},
   "source": [
    "Making data for category training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb113f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d8d93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data=data[['input_text','product_group_name']].copy(deep=False)\n",
    "cat_data['input_text']=cat_data['input_text']+' [opt] '+' [opt] '.join(cats)\n",
    "\n",
    "cat_sss=StratifiedShuffleSplit(train_size=0.02,random_state=42)\n",
    "\n",
    "cat_gen=cat_sss.split(cat_data['input_text'],cat_data['product_group_name'])\n",
    "cat_data=cat_data.iloc[next(cat_gen)[0]]\n",
    "\n",
    "cat_data.reset_index(inplace=True)\n",
    "cat_data.drop('index',axis=1,inplace=True)\n",
    "\n",
    "cat_data.columns=['input_text','target_text']\n",
    "\n",
    "cat_data['prefix']='translate input_text to target_text'\n",
    "\n",
    "cat_train_data=cat_data[:10000]\n",
    "cat_eval_data=cat_data[10000:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b94e96c5",
   "metadata": {},
   "source": [
    "Making data for subcategory training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca1ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d3386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat_data=data[['input_text','product_type_name']].copy(deep=False)\n",
    "subcat_data['input_text']=subcat_data['input_text']+' [opt] '+' [opt] '.join(subcats)\n",
    "\n",
    "subcat_sss=StratifiedShuffleSplit(train_size=0.02,random_state=42)\n",
    "\n",
    "subcat_gen=subcat_sss.split(subcat_data['input_text'],subcat_data['product_type_name'])\n",
    "subcat_data=subcat_data.iloc[next(subcat_gen)[0]]\n",
    "\n",
    "subcat_data.reset_index(inplace=True)\n",
    "subcat_data.drop('index',axis=1,inplace=True)\n",
    "\n",
    "subcat_data.columns=['input_text','target_text']\n",
    "\n",
    "subcat_data['prefix']='translate input_text to target_text'\n",
    "\n",
    "subcat_train_data=subcat_data[:10000]\n",
    "subcat_eval_data=subcat_data[10000:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62135fc8",
   "metadata": {},
   "source": [
    "Model training for catrgory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2159bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from simpletransformers.t5 import T5Model,T5Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be7ca604",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger=logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a3dfe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_seq_len=max(cat_data['input_text'].apply(lambda x:len(x.split())))\n",
    "cat_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e273d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcat_seq_len=max(subcat_data['input_text'].apply(lambda x:len(x.split())))\n",
    "subcat_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f826bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\Anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##specifying model arguments\n",
    "model_args = T5Args()\n",
    "model_args.max_seq_length=subcat_seq_len\n",
    "model_args.train_batch_size=128\n",
    "model_args.eval_batch_size=128\n",
    "model_args.num_train_epochs=1\n",
    "##model_args.evaluate_during_training = True\n",
    "##model_args.evaluate_during_training_steps = 30000\n",
    "model_args.use_multiprocessing=False\n",
    "model_args.fp16=False\n",
    "model_args.save_steps=-1\n",
    "model_args.save_eval_checkpoints=False\n",
    "model_args.no_cache=True\n",
    "model_args.reprocess_input_data=True\n",
    "model_args.overwrite_output_dir=True\n",
    "model_args.preprocess_inputs=False\n",
    "model_args.num_return_sequences=1\n",
    "\n",
    "##instantiating the model\n",
    "model=T5Model(\"t5\",\"t5-small\",args=model_args,use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00125c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccca2812dc24119b7c4fd762b8a9966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3538: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "INFO:simpletransformers.t5.t5_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cbbec49eb0487ca8f5682fbd925b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8e34a06e4e4bea8dfc071223875f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: Training of t5-small model complete. Saved to outputs/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79, 0.653274255085595)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train_data=cat_train_data,eval_data=cat_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a74a61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a03784f9bd4ad9a454dda7a929e5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89bb3e9d68f4f99b72e76413cba18a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aad8aa545db4b75a6120437af62459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: Training of t5-small model complete. Saved to outputs/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79, 0.9463934664484821)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train_data=subcat_train_data,eval_data=subcat_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d1904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e99ff1f95a4d30b1801f4e6ecd6132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3538: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84265fcda6e244849a79dfcc029f3849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/2665 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m cat_eval_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(cat_eval_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m cat_eval_pred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(cat_eval_input)\n\u001b[1;32m----> 4\u001b[0m cat_acc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target,prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43meval_target\u001b[49m,eval_pred) \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m==\u001b[39mprediction)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(cat_eval_input)\n\u001b[0;32m      5\u001b[0m cat_acc\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eval_target' is not defined"
     ]
    }
   ],
   "source": [
    "cat_eval_input=list(cat_eval_data['input_text'])\n",
    "cat_eval_target=list(cat_eval_data['target_text'])\n",
    "cat_eval_pred=model.predict(cat_eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815752d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08930581613508443"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_acc=sum(1 for target,prediction in zip(cat_eval_target,cat_eval_pred) if target==prediction)/len(cat_eval_input)\n",
    "cat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f66f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9c110029ac442eb49a3eb42a626f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ba5d3bdf4f4ec9b1937c8e39cb478f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/2665 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subcat_eval_input=list(subcat_eval_data['input_text'])\n",
    "subcat_eval_target=list(subcat_eval_data['target_text'])\n",
    "subcat_eval_pred=model.predict(subcat_eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16232b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475797373358349"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcat_acc=sum(1 for target,prediction in zip(subcat_eval_target,subcat_eval_pred) if target==prediction)/len(subcat_eval_input)\n",
    "subcat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f04952f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12278e7127f84eba868488fda7d5400b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3e4ed7beed47de87210e14c95f7970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Garment Lower body']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('shirt'+' [opt] '+' [opt] '.join(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c1cf635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Garment Upper body [opt] Garment Lower body [opt] Garment Full body [opt] Accessories'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' [opt] '.join(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7b64323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed4a1e8340a4c5c8523049033823341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3538: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329968ceac554ffba984267d9eda171f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Body Body']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('shirt'+' [opt] '+'Garment Upper body [opt] Garment Full body [opt] Accessories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bdd289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5a2fe0ddd848279d5d0e2208f5ec90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5dd520ad14e61bedea84aa390d69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Body Body']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('skirt'+' [opt] '+'Garment Upper body [opt] Garment Lower body [opt] Accessories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee6433d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2e7c85adc0498daa0e42fd1cc3315d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70621aeb68b94680a7c29e8bd129b9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Ski Ski Ski']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('skirt'+' [opt] '+'Garment Upper body [opt] Garment Full body [opt] Accessories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2657f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce834630bdcf481ba43fe2e88f88f99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhsingh73\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3538: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1899fcbde28d4bae8b0a514dcf1398a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Skirt', 'Leggings/Tights', 'no no icesuit', 'no_subcategory']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('skirt'+' [opt] '+' [opt] '.join(subcats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad2db08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347bad3ee6dd48c4898d10839c9dfdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247ed2aae75e444495c86e3f6dc7daee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Blouse', 'no_subcategory', 'Dress', 'Hair/alice band']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('shirt'+' [opt] '+' [opt] '.join(subcats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04bfd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(output_dir='t5_scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c977dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "outputs/t5_scrap is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py:283\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py:494\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    493\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mhead(url, headers\u001b[38;5;241m=\u001b[39mheaders, allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout)\n\u001b[1;32m--> 494\u001b[0m \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m etag \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Linked-Etag\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py:416\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;66;03m# The repo was not found and the user is not Authenticated\u001b[39;00m\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m401 Client Error: Repository not found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the repo is private, make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m     )\n\u001b[0;32m    421\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error: Repository not found for url: https://huggingface.co/outputs/t5_scrap/resolve/main/config.json. If the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mT5Model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs/t5_scrap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\simpletransformers\\t5\\t5_model.py:129\u001b[0m, in \u001b[0;36mT5Model.__init__\u001b[1;34m(self, model_type, model_name, args, tokenizer, use_cuda, cuda_device, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_class(config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokenizer, T5Tokenizer):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:526\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m     config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m    528\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    529\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    531\u001b[0m         )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_files\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:613\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_path(\n\u001b[0;32m    602\u001b[0m         config_file,\n\u001b[0;32m    603\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier listed on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token having \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists for this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    622\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel name. Check the model page at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    624\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: outputs/t5_scrap is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "model=T5Model('t5','outputs/t5_scrap',use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157feb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
